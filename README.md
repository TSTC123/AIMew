# 本地部署
如果想实现AI功能，我在这里面采用了本地部署AI

没法子，我不能自己训练一个AI吧，在多方对比后和需求分析，我采用了了本地推理方案，模型推理引擎选择Ollama,采用的AI模型是Qwen2.5

可离线使用，不过我是提前下好Ollama搭建好AI模型，然后在AIMew中调用端口，这种操做并不是很方便，或许后面可以修改代码去，调用网上的API端口

嗯，有点智障，如果可以以后去选用更好的推理引擎和模型，现在先将就着用

# 展示界面
运行界面大概是这样
<img width="870" height="723" alt="image" src="https://github.com/user-attachments/assets/cf666af0-57c6-4150-a972-ad5439cec2ff" />
